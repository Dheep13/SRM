{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RMSE: 51.66\n",
      "Fold 2 RMSE: 46.91\n",
      "Fold 3 RMSE: 64.08\n",
      "Fold 4 RMSE: 53.51\n",
      "Fold 5 RMSE: 45.60\n",
      "\n",
      "Mean RMSE: 52.35 (+/- 6.55)\n",
      "\n",
      "Top 10 Important Features:\n",
      "                      feature  importance\n",
      "0                  total_sqft    0.198666\n",
      "1              log_total_sqft    0.169200\n",
      "12    price_per_sqft_loc_mean    0.155214\n",
      "5                        bath    0.116582\n",
      "9       location_price_median    0.054946\n",
      "8         location_price_mean    0.052585\n",
      "15         location_price_std    0.041374\n",
      "14        price_to_dist_ratio    0.040576\n",
      "6                        size    0.035747\n",
      "13  price_per_sqft_loc_median    0.030530\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "\n",
    "class HousePricePredictor:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        self.location_stats = None\n",
    "        self.features = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.train = pd.read_csv('train.csv')\n",
    "        self.test = pd.read_csv('test.csv')\n",
    "        self.rent_data = pd.read_csv('avg_rent.csv')\n",
    "        self.dist_data = pd.read_csv('dist_from_city_centre.csv')\n",
    "        \n",
    "    def clean_size(self, size):\n",
    "        if pd.isna(size):\n",
    "            return np.nan\n",
    "        nums = re.findall(r'\\d+', str(size))\n",
    "        if nums:\n",
    "            return float(nums[0])\n",
    "        return np.nan\n",
    "    \n",
    "    def clean_total_sqft(self, sqft):\n",
    "        if pd.isna(sqft):\n",
    "            return np.nan\n",
    "        try:\n",
    "            if '-' in str(sqft):\n",
    "                nums = [float(x.strip()) for x in sqft.split('-')]\n",
    "                return sum(nums)/len(nums)\n",
    "            return float(sqft)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Clean size and sqft\n",
    "        df['size'] = df['size'].apply(self.clean_size)\n",
    "        df['total_sqft'] = df['total_sqft'].apply(self.clean_total_sqft)\n",
    "        \n",
    "        # Remove outliers for training data\n",
    "        if is_train:\n",
    "            df = df[df['total_sqft'] < df['total_sqft'].quantile(0.99)]\n",
    "            df = df[df['bath'] < df['bath'].quantile(0.99)]\n",
    "        \n",
    "        # Handle missing values\n",
    "        df['size'] = df['size'].fillna(df['size'].median())\n",
    "        df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "        df['balcony'] = df['balcony'].fillna(df['balcony'].median())\n",
    "        \n",
    "        # Transform area_type\n",
    "        if is_train:\n",
    "            df['area_type'] = self.le.fit_transform(df['area_type'])\n",
    "        else:\n",
    "            df['area_type'] = self.le.transform(df['area_type'])\n",
    "        \n",
    "        df['has_society'] = df['society'].notna().astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Merge additional data\n",
    "        df = df.merge(self.rent_data, on='location', how='left')\n",
    "        df = df.merge(self.dist_data, on='location', how='left')\n",
    "        \n",
    "        # Handle missing values in merged features\n",
    "        df['avg_2bhk_rent'] = df['avg_2bhk_rent'].fillna(df['avg_2bhk_rent'].mean())\n",
    "        df['dist_from_city'] = df['dist_from_city'].fillna(df['dist_from_city'].mean())\n",
    "        \n",
    "        # Enhanced size-based features\n",
    "        df['log_total_sqft'] = np.log1p(df['total_sqft'])\n",
    "        df['total_sqft_squared'] = df['total_sqft'] ** 2\n",
    "        df['total_sqft_per_bath'] = df['total_sqft'] / (df['bath'] + 1)\n",
    "        df['total_sqft_per_balcony'] = df['total_sqft'] / (df['balcony'] + 1)\n",
    "        \n",
    "        # Enhanced location features\n",
    "        if is_train:\n",
    "            self.location_stats = df.groupby('location').agg({\n",
    "                'price': ['mean', 'median', 'std', 'count'],\n",
    "                'total_sqft': ['mean', 'median']\n",
    "            })\n",
    "        \n",
    "        # Add location features\n",
    "        for stat in ['mean', 'median']:\n",
    "            df[f'location_price_{stat}'] = df['location'].map(self.location_stats['price'][stat])\n",
    "            df[f'location_sqft_{stat}'] = df['location'].map(self.location_stats['total_sqft'][stat])\n",
    "        \n",
    "        # Location price variance\n",
    "        df['location_price_std'] = df['location'].map(self.location_stats['price']['std'])\n",
    "        \n",
    "        # Fill missing location stats with means\n",
    "        location_means = {col: self.location_stats[col[0]][col[1]].mean() \n",
    "                         for col in self.location_stats.columns}\n",
    "        df = df.fillna(location_means)\n",
    "        \n",
    "        # Price per sqft features\n",
    "        df['price_per_sqft_loc_mean'] = df['location_price_mean'] / df['location_sqft_mean']\n",
    "        df['price_per_sqft_loc_median'] = df['location_price_median'] / df['location_sqft_median']\n",
    "        \n",
    "        # Distance-based features\n",
    "        df['price_to_dist_ratio'] = df['location_price_mean'] / (df['dist_from_city'] + 1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def prepare_features(self, df, is_train=True):\n",
    "        if self.features is None:\n",
    "            self.features = [\n",
    "                'total_sqft', 'log_total_sqft', 'total_sqft_squared',\n",
    "                'total_sqft_per_bath', 'total_sqft_per_balcony',\n",
    "                'bath', 'size', 'dist_from_city',\n",
    "                'location_price_mean', 'location_price_median',\n",
    "                'location_sqft_mean', 'location_sqft_median',\n",
    "                'price_per_sqft_loc_mean', 'price_per_sqft_loc_median',\n",
    "                'price_to_dist_ratio', 'location_price_std'\n",
    "            ]\n",
    "            \n",
    "        X = df[self.features]\n",
    "        \n",
    "        if is_train:\n",
    "            X = pd.DataFrame(self.scaler.fit_transform(X), columns=self.features)\n",
    "        else:\n",
    "            X = pd.DataFrame(self.scaler.transform(X), columns=self.features)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def train_model(self):\n",
    "        # Preprocess data\n",
    "        self.train = self.preprocess_data(self.train, is_train=True)\n",
    "        self.train = self.engineer_features(self.train, is_train=True)\n",
    "        \n",
    "        X = self.prepare_features(self.train, is_train=True)\n",
    "        y = self.train['price']\n",
    "        \n",
    "        # Cross validation setup\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rmse_scores = []\n",
    "        \n",
    "        # Train with cross validation\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.03,\n",
    "                max_depth=6,\n",
    "                min_child_weight=2,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.5,\n",
    "                reg_lambda=0.5,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            rmse_scores.append(rmse)\n",
    "            print(f\"Fold {fold} RMSE: {rmse:.2f}\")\n",
    "        \n",
    "        print(f\"\\nMean RMSE: {np.mean(rmse_scores):.2f} (+/- {np.std(rmse_scores):.2f})\")\n",
    "        \n",
    "        # Train final model on full data\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=6,\n",
    "            min_child_weight=2,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=0.5,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # Feature importance\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nTop 10 Important Features:\")\n",
    "        print(importance_df.head(10))\n",
    "        \n",
    "    def predict(self):\n",
    "        self.test = self.preprocess_data(self.test, is_train=False)\n",
    "        self.test = self.engineer_features(self.test, is_train=False)\n",
    "        X_test = self.prepare_features(self.test, is_train=False)\n",
    "        \n",
    "        predictions = self.model.predict(X_test)\n",
    "        \n",
    "        submission = pd.DataFrame({\n",
    "            'ID': range(len(predictions)),\n",
    "            'Price': predictions\n",
    "        })\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = HousePricePredictor()\n",
    "    predictor.load_data()\n",
    "    predictor.train_model()\n",
    "    predictor.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting House Price Prediction...\n",
      "Loading datasets...\n",
      "Datasets loaded successfully!\n",
      "\n",
      "Starting model training...\n",
      "Preprocessing data...\n",
      "Removing outliers...\n",
      "Preparing features for modeling...\n",
      "\n",
      "Error occurred: \"['price_per_sqft', 'total_sqft_per_bath', 'sqft_per_room'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import re\n",
    "\n",
    "class HousePricePredictor:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.scaler = RobustScaler()\n",
    "        self.model = None\n",
    "        self.location_stats = None\n",
    "        self.features = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        print(\"Loading datasets...\")\n",
    "        self.train = pd.read_csv('train.csv')\n",
    "        self.test = pd.read_csv('test.csv')\n",
    "        self.rent_data = pd.read_csv('avg_rent.csv')\n",
    "        self.dist_data = pd.read_csv('dist_from_city_centre.csv')\n",
    "        print(\"Datasets loaded successfully!\")\n",
    "        \n",
    "    def clean_size(self, size):\n",
    "        if pd.isna(size):\n",
    "            return np.nan\n",
    "        nums = re.findall(r'\\d+', str(size))\n",
    "        if nums:\n",
    "            return float(nums[0])\n",
    "        return np.nan\n",
    "    \n",
    "    def clean_total_sqft(self, sqft):\n",
    "        if pd.isna(sqft):\n",
    "            return np.nan\n",
    "        try:\n",
    "            if '-' in str(sqft):\n",
    "                nums = [float(x.strip()) for x in sqft.split('-')]\n",
    "                return sum(nums)/len(nums)\n",
    "            return float(sqft)\n",
    "        except:\n",
    "            return np.nan\n",
    "            \n",
    "    def remove_outliers(self, df):\n",
    "        print(\"Removing outliers...\")\n",
    "        df = df.copy()\n",
    "        for column in ['total_sqft', 'bath', 'price']:\n",
    "            if column in df.columns:\n",
    "                Q1 = df[column].quantile(0.25)\n",
    "                Q3 = df[column].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                df = df[~((df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR)))]\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        print(\"Preprocessing data...\")\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Clean size and sqft\n",
    "        df['size'] = df['size'].apply(self.clean_size)\n",
    "        df['total_sqft'] = df['total_sqft'].apply(self.clean_total_sqft)\n",
    "        \n",
    "        # Handle missing values\n",
    "        df['size'] = df['size'].fillna(df['size'].median())\n",
    "        df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "        df['balcony'] = df['balcony'].fillna(df['balcony'].median())\n",
    "        \n",
    "        # Transform area_type\n",
    "        if is_train:\n",
    "            df['area_type'] = self.le.fit_transform(df['area_type'])\n",
    "        else:\n",
    "            df['area_type'] = self.le.transform(df['area_type'])\n",
    "        \n",
    "        df['has_society'] = df['society'].notna().astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Merge additional data\n",
    "        df = df.merge(self.rent_data, on='location', how='left')\n",
    "        df = df.merge(self.dist_data, on='location', how='left')\n",
    "        \n",
    "        # Handle missing values for numeric columns first\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "        \n",
    "        # Area features\n",
    "        df['log_total_sqft'] = np.log1p(df['total_sqft'])\n",
    "        df['total_sqft_squared'] = df['total_sqft'] ** 2\n",
    "        df['sqft_per_bedroom'] = df['total_sqft']/df['size']\n",
    "        \n",
    "        # Bath features\n",
    "        df['bath_ratio'] = df['bath']/df['size']\n",
    "        df['bath_per_sqft'] = df['bath']*1000/df['total_sqft']\n",
    "        \n",
    "        # Location features\n",
    "        if is_train:\n",
    "            self.location_stats = df.groupby('location').agg({\n",
    "                'price': ['mean', 'median', 'std'],\n",
    "                'total_sqft': ['mean'],\n",
    "                'bath': ['mean']\n",
    "            })\n",
    "        \n",
    "        # Add location features\n",
    "        df['location_price_mean'] = df['location'].map(self.location_stats['price']['mean'])\n",
    "        df['location_price_median'] = df['location'].map(self.location_stats['price']['median'])\n",
    "        df['location_sqft_mean'] = df['location'].map(self.location_stats['total_sqft']['mean'])\n",
    "        \n",
    "        # Fill missing location features with global means\n",
    "        location_features = ['location_price_mean', 'location_price_median', 'location_sqft_mean']\n",
    "        for col in location_features:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        \n",
    "        # Distance features\n",
    "        df['log_dist_from_city'] = np.log1p(df['dist_from_city'])\n",
    "        df['price_to_dist_ratio'] = df['location_price_mean'] / (df['dist_from_city'] + 1)\n",
    "        \n",
    "        # Fill any remaining numeric columns\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def prepare_features(self, df, is_train=True):\n",
    "        print(\"Preparing features for modeling...\")\n",
    "        if self.features is None:\n",
    "            self.features = [\n",
    "                'total_sqft', 'log_total_sqft', 'total_sqft_squared',\n",
    "                'bath', 'size', 'dist_from_city',\n",
    "                'location_price_mean', 'location_price_median',\n",
    "                'price_per_sqft', 'price_to_dist_ratio',\n",
    "                'total_sqft_per_bath', 'sqft_per_room'\n",
    "            ]\n",
    "            \n",
    "        X = df[self.features]\n",
    "        \n",
    "        if is_train:\n",
    "            X = pd.DataFrame(self.scaler.fit_transform(X), columns=self.features)\n",
    "        else:\n",
    "            X = pd.DataFrame(self.scaler.transform(X), columns=self.features)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def train_model(self):\n",
    "        print(\"\\nStarting model training...\")\n",
    "        \n",
    "        # Preprocess data\n",
    "        self.train = self.preprocess_data(self.train, is_train=True)\n",
    "        self.train = self.remove_outliers(self.train)\n",
    "        self.train = self.engineer_features(self.train, is_train=True)\n",
    "        \n",
    "        # Prepare features\n",
    "        X = self.prepare_features(self.train, is_train=True)\n",
    "        y = self.train['price']\n",
    "        \n",
    "        # Cross validation\n",
    "        print(\"\\nPerforming cross-validation...\")\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rmse_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=6,\n",
    "                min_child_weight=3,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.7,\n",
    "                reg_alpha=1,\n",
    "                reg_lambda=1,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            rmse_scores.append(rmse)\n",
    "            print(f\"Fold {fold} RMSE: {rmse:.2f}\")\n",
    "        \n",
    "        print(f\"\\nMean RMSE: {np.mean(rmse_scores):.2f} (+/- {np.std(rmse_scores):.2f})\")\n",
    "        \n",
    "        # Train final model on all data\n",
    "        print(\"\\nTraining final model on full dataset...\")\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            min_child_weight=3,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            reg_alpha=1,\n",
    "            reg_lambda=1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # Feature importance\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nTop 10 Important Features:\")\n",
    "        print(importance_df.head(10))\n",
    "        \n",
    "    def predict(self):\n",
    "        print(\"\\nGenerating predictions...\")\n",
    "        # Preprocess test data\n",
    "        self.test = self.preprocess_data(self.test, is_train=False)\n",
    "        self.test = self.engineer_features(self.test, is_train=False)\n",
    "        X_test = self.prepare_features(self.test, is_train=False)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(X_test)\n",
    "        \n",
    "        # Create submission file\n",
    "        submission = pd.DataFrame({\n",
    "            'ID': range(len(predictions)),\n",
    "            'Price': predictions\n",
    "        })\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "        print(\"\\nPredictions saved to 'submission.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Starting House Price Prediction...\")\n",
    "        predictor = HousePricePredictor()\n",
    "        predictor.load_data()\n",
    "        predictor.train_model()\n",
    "        predictor.predict()\n",
    "        print(\"\\nProcess completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Data loading completed successfully.\n",
      "Starting model training...\n",
      "Fold 1 RMSE: 43.87\n",
      "Fold 2 RMSE: 53.35\n",
      "Fold 3 RMSE: 54.94\n",
      "Fold 4 RMSE: 50.86\n",
      "Fold 5 RMSE: 47.59\n",
      "\n",
      "Mean RMSE: 50.12 (+/- 3.99)\n",
      "Generating predictions...\n",
      "Predictions saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "\n",
    "class HousePricePredictor:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        self.location_stats = None\n",
    "        self.features = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load all required datasets\"\"\"\n",
    "        try:\n",
    "            print(\"Loading datasets...\")\n",
    "            self.train = pd.read_csv('train.csv')\n",
    "            self.test = pd.read_csv('test.csv')\n",
    "            self.rent_data = pd.read_csv('avg_rent.csv')\n",
    "            self.dist_data = pd.read_csv('dist_from_city_centre.csv')\n",
    "            print(\"Data loading completed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def clean_size(self, size):\n",
    "        if pd.isna(size):\n",
    "            return np.nan\n",
    "        nums = re.findall(r'\\d+', str(size))\n",
    "        if nums:\n",
    "            return float(nums[0])\n",
    "        return np.nan\n",
    "    \n",
    "    def clean_total_sqft(self, sqft):\n",
    "        if pd.isna(sqft):\n",
    "            return np.nan\n",
    "        try:\n",
    "            if '-' in str(sqft):\n",
    "                nums = [float(x.strip()) for x in sqft.split('-')]\n",
    "                return sum(nums)/len(nums)\n",
    "            return float(sqft)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def remove_outliers(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Price per square foot outliers\n",
    "        df['price_per_sqft'] = df['price']*100000/df['total_sqft']\n",
    "        \n",
    "        for location in df['location'].unique():\n",
    "            location_df = df[df['location'] == location]\n",
    "            if len(location_df) > 10:\n",
    "                mean = location_df['price_per_sqft'].mean()\n",
    "                std = location_df['price_per_sqft'].std()\n",
    "                df = df[~((df['location'] == location) & \n",
    "                         (df['price_per_sqft'] > mean + 3*std))]\n",
    "        \n",
    "        # Bathroom outliers\n",
    "        df = df[df['bath'] <= df['size'] + 2]\n",
    "        \n",
    "        # Area per bedroom outliers\n",
    "        df['sqft_per_bedroom'] = df['total_sqft']/df['size']\n",
    "        df = df[(df['sqft_per_bedroom'] >= 300) & \n",
    "                (df['sqft_per_bedroom'] <= 3000)]\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Clean size and sqft\n",
    "        df['size'] = df['size'].apply(self.clean_size)\n",
    "        df['total_sqft'] = df['total_sqft'].apply(self.clean_total_sqft)\n",
    "        \n",
    "        # Handle missing values\n",
    "        df['size'] = df['size'].fillna(df['size'].median())\n",
    "        df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "        df['balcony'] = df['balcony'].fillna(df['balcony'].median())\n",
    "        \n",
    "        if is_train:\n",
    "            df = self.remove_outliers(df)\n",
    "        \n",
    "        # Transform area_type\n",
    "        if is_train:\n",
    "            df['area_type'] = self.le.fit_transform(df['area_type'])\n",
    "        else:\n",
    "            df['area_type'] = self.le.transform(df['area_type'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Merge additional data\n",
    "        df = df.merge(self.rent_data, on='location', how='left')\n",
    "        df = df.merge(self.dist_data, on='location', how='left')\n",
    "        \n",
    "        # Handle missing values for numeric columns first\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "        \n",
    "        # Area features\n",
    "        df['log_total_sqft'] = np.log1p(df['total_sqft'])\n",
    "        df['total_sqft_squared'] = df['total_sqft'] ** 2\n",
    "        df['sqft_per_bedroom'] = df['total_sqft']/df['size']\n",
    "        \n",
    "        # Bath features\n",
    "        df['bath_ratio'] = df['bath']/df['size']\n",
    "        df['bath_per_sqft'] = df['bath']*1000/df['total_sqft']\n",
    "        \n",
    "        # Location features\n",
    "        if is_train:\n",
    "            self.location_stats = df.groupby('location').agg({\n",
    "                'price': ['mean', 'median', 'std'],\n",
    "                'total_sqft': ['mean'],\n",
    "                'bath': ['mean']\n",
    "            })\n",
    "        \n",
    "        # Add location features\n",
    "        df['location_price_mean'] = df['location'].map(self.location_stats['price']['mean'])\n",
    "        df['location_price_median'] = df['location'].map(self.location_stats['price']['median'])\n",
    "        df['location_sqft_mean'] = df['location'].map(self.location_stats['total_sqft']['mean'])\n",
    "        \n",
    "        # Fill missing location features with global means\n",
    "        location_features = ['location_price_mean', 'location_price_median', 'location_sqft_mean']\n",
    "        for col in location_features:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        \n",
    "        # Distance features\n",
    "        df['log_dist_from_city'] = np.log1p(df['dist_from_city'])\n",
    "        df['price_to_dist_ratio'] = df['location_price_mean'] / (df['dist_from_city'] + 1)\n",
    "        \n",
    "        # Fill any remaining numeric columns\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def prepare_features(self, df, is_train=True):\n",
    "        if self.features is None:\n",
    "            self.features = [\n",
    "                'total_sqft', 'log_total_sqft', 'sqft_per_bedroom',\n",
    "                'bath', 'bath_ratio', 'bath_per_sqft',\n",
    "                'size', 'log_dist_from_city',\n",
    "                'location_price_mean', 'location_sqft_mean',\n",
    "                'price_to_dist_ratio', 'area_type',\n",
    "                'avg_2bhk_rent'\n",
    "            ]\n",
    "            \n",
    "        X = df[self.features]\n",
    "        \n",
    "        if is_train:\n",
    "            X = pd.DataFrame(self.scaler.fit_transform(X), columns=self.features)\n",
    "        else:\n",
    "            X = pd.DataFrame(self.scaler.transform(X), columns=self.features)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def train_model(self):\n",
    "        print(\"Starting model training...\")\n",
    "        self.train = self.preprocess_data(self.train, is_train=True)\n",
    "        self.train = self.engineer_features(self.train, is_train=True)\n",
    "        \n",
    "        X = self.prepare_features(self.train, is_train=True)\n",
    "        y = self.train['price']\n",
    "        \n",
    "        # Cross validation\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rmse_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=7,\n",
    "                min_child_weight=3,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.7,\n",
    "                reg_alpha=0.75,\n",
    "                reg_lambda=0.75,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            rmse_scores.append(rmse)\n",
    "            print(f\"Fold {fold} RMSE: {rmse:.2f}\")\n",
    "        \n",
    "        print(f\"\\nMean RMSE: {np.mean(rmse_scores):.2f} (+/- {np.std(rmse_scores):.2f})\")\n",
    "        \n",
    "        # Train final model\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=1200,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=7,\n",
    "            min_child_weight=3,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            reg_alpha=0.75,\n",
    "            reg_lambda=0.75,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self):\n",
    "        print(\"Generating predictions...\")\n",
    "        self.test = self.preprocess_data(self.test, is_train=False)\n",
    "        self.test = self.engineer_features(self.test, is_train=False)\n",
    "        X_test = self.prepare_features(self.test, is_train=False)\n",
    "        \n",
    "        predictions = self.model.predict(X_test)\n",
    "        \n",
    "        submission = pd.DataFrame({\n",
    "            'ID': range(len(predictions)),\n",
    "            'Price': predictions\n",
    "        })\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "        print(\"Predictions saved to 'submission.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = HousePricePredictor()\n",
    "    predictor.load_data()\n",
    "    predictor.train_model()\n",
    "    predictor.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def engineer_features(self, df, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Merge additional data\n",
    "    df = df.merge(self.rent_data, on='location', how='left')\n",
    "    df = df.merge(self.dist_data, on='location', how='left')\n",
    "    \n",
    "    # Handle missing numerics\n",
    "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "    \n",
    "    # Enhanced area features\n",
    "    df['log_total_sqft'] = np.log1p(df['total_sqft'])\n",
    "    df['total_sqft_squared'] = df['total_sqft'] ** 2\n",
    "    df['sqft_per_bedroom'] = df['total_sqft']/df['size']\n",
    "    df['sqft_per_bath'] = df['total_sqft']/df['bath']\n",
    "    \n",
    "    # Price per sqft features (for training)\n",
    "    if 'price' in df.columns:\n",
    "        df['price_per_sqft'] = df['price']*100000/df['total_sqft']\n",
    "    \n",
    "    # Enhanced bath features\n",
    "    df['bath_ratio'] = df['bath']/df['size']\n",
    "    df['bath_per_sqft'] = df['bath']*1000/df['total_sqft']\n",
    "    df['extra_bath'] = df['bath'] - df['size']  # Extra bathrooms beyond bedrooms\n",
    "    \n",
    "    # Location clustering\n",
    "    if is_train:\n",
    "        self.location_stats = df.groupby('location').agg({\n",
    "            'price': ['count', 'mean', 'median', 'std'],\n",
    "            'total_sqft': ['mean', 'std'],\n",
    "            'bath': ['mean'],\n",
    "            'size': ['mean'],\n",
    "            'price_per_sqft': ['mean', 'std']\n",
    "        })\n",
    "        \n",
    "        # Create location clusters based on price_per_sqft\n",
    "        self.location_clusters = pd.qcut(\n",
    "            self.location_stats['price_per_sqft']['mean'], \n",
    "            q=10, \n",
    "            labels=['cluster_'+str(i) for i in range(10)]\n",
    "        )\n",
    "    \n",
    "    # Add location features with smoothing\n",
    "    for stat in ['mean', 'median']:\n",
    "        df[f'location_price_{stat}'] = df['location'].map(self.location_stats['price'][stat])\n",
    "    \n",
    "    df['location_price_std'] = df['location'].map(self.location_stats['price']['std'])\n",
    "    df['location_density'] = df['location'].map(self.location_stats['price']['count'])\n",
    "    \n",
    "    # Location cluster features\n",
    "    df['location_cluster'] = df['location'].map(self.location_clusters)\n",
    "    df['cluster_encoded'] = self.le.fit_transform(df['location_cluster']) if is_train else \\\n",
    "                           self.le.transform(df['location_cluster'])\n",
    "    \n",
    "    # Enhanced distance features\n",
    "    df['log_dist_from_city'] = np.log1p(df['dist_from_city'])\n",
    "    df['dist_squared'] = df['dist_from_city'] ** 2\n",
    "    df['price_to_dist_ratio'] = df['location_price_mean'] / (df['dist_from_city'] + 1)\n",
    "    \n",
    "    # Rent features\n",
    "    df['rent_ratio'] = df['avg_2bhk_rent'] / df['total_sqft']\n",
    "    df['rent_to_price'] = df['avg_2bhk_rent'] / df['location_price_mean']\n",
    "    \n",
    "    # Interaction features\n",
    "    df['sqft_dist'] = df['log_total_sqft'] * df['log_dist_from_city']\n",
    "    df['sqft_bath'] = df['log_total_sqft'] * df['bath_ratio']\n",
    "    df['sqft_cluster'] = df['log_total_sqft'] * df['cluster_encoded']\n",
    "    \n",
    "    # Fill missing values\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_model(self):\n",
    "\n",
    "    model_params = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 4,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.5,\n",
    "    'reg_lambda': 0.5,\n",
    "    'random_state': 42,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'gamma': 0.1\n",
    "}\n",
    "\n",
    "    # Use k-fold cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)  # Increased folds\n",
    "\n",
    "    # Train multiple models\n",
    "    models = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = xgb.XGBRegressor(**model_params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        models.append(model)\n",
    "        val_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "        print(f\"Fold {fold} RMSE: {rmse:.2f}\")\n",
    "\n",
    "    # Use model averaging for final predictions\n",
    "    self.models = models\n",
    "        # Use k-fold cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)  # Increased folds\n",
    "    \n",
    "    # Train multiple models\n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = xgb.XGBRegressor(**model_params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        models.append(model)\n",
    "        val_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "        print(f\"Fold {fold} RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    # Use model averaging for final predictions\n",
    "    self.models = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Starting model training...\n",
      "Preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepanShanmugam\\AppData\\Local\\Temp\\ipykernel_9988\\4179253980.py:91: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  self.price_stats = df.groupby('location')['price'].agg(['mean', 'median', 'std']).fillna(method='ffill')\n",
      "C:\\Users\\DeepanShanmugam\\AppData\\Local\\Temp\\ipykernel_9988\\4179253980.py:59: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  }).fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4914\n",
      "[LightGBM] [Info] Number of data points in the train set: 7887, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 108.600595\n",
      "Fold 1 RMSE: 68.55\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4931\n",
      "[LightGBM] [Info] Number of data points in the train set: 7887, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 106.527115\n",
      "Fold 2 RMSE: 75.82\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4927\n",
      "[LightGBM] [Info] Number of data points in the train set: 7887, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 106.218259\n",
      "Fold 3 RMSE: 71.06\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4922\n",
      "[LightGBM] [Info] Number of data points in the train set: 7887, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 108.177129\n",
      "Fold 4 RMSE: 59.62\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4918\n",
      "[LightGBM] [Info] Number of data points in the train set: 7888, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 107.494397\n",
      "Fold 5 RMSE: 81.48\n",
      "Generating predictions...\n",
      "Preprocessing data...\n",
      "Predictions saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "\n",
    "class HousePricePredictor:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = None\n",
    "        self.location_stats = None\n",
    "        self.features = None\n",
    "        self.poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        \n",
    "    def load_data(self):\n",
    "        print(\"Loading datasets...\")\n",
    "        self.train = pd.read_csv('train.csv')\n",
    "        self.test = pd.read_csv('test.csv')\n",
    "        self.rent_data = pd.read_csv('avg_rent.csv')\n",
    "        self.dist_data = pd.read_csv('dist_from_city_centre.csv')\n",
    "        \n",
    "    def clean_size(self, size):\n",
    "        if pd.isna(size):\n",
    "            return np.nan\n",
    "        nums = re.findall(r'\\d+', str(size))\n",
    "        if nums:\n",
    "            return float(nums[0])\n",
    "        return np.nan\n",
    "    \n",
    "    def clean_total_sqft(self, sqft):\n",
    "        if pd.isna(sqft):\n",
    "            return np.nan\n",
    "        try:\n",
    "            if '-' in str(sqft):\n",
    "                nums = [float(x.strip()) for x in sqft.split('-')]\n",
    "                return sum(nums)/len(nums)\n",
    "            return float(sqft)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def create_location_features(self, df):\n",
    "        # Create location clusters\n",
    "        location_price_map = df.groupby('location')['price'].mean().to_dict() if 'price' in df.columns else self.location_price_map\n",
    "        df['location_price'] = df['location'].map(location_price_map)\n",
    "        \n",
    "        # Location clustering\n",
    "        if not hasattr(self, 'kmeans'):\n",
    "            loc_features = df.groupby('location').agg({\n",
    "                'total_sqft': 'mean',\n",
    "                'bath': 'mean',\n",
    "                'dist_from_city': 'mean',\n",
    "                'avg_2bhk_rent': 'mean'\n",
    "            }).fillna(method='ffill')\n",
    "            \n",
    "            self.kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "            self.kmeans.fit(loc_features)\n",
    "            self.location_clusters = {loc: cluster for loc, cluster in zip(loc_features.index, self.kmeans.labels_)}\n",
    "            \n",
    "        df['location_cluster'] = df['location'].map(self.location_clusters)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Merge additional data\n",
    "        df = df.merge(self.rent_data, on='location', how='left')\n",
    "        df = df.merge(self.dist_data, on='location', how='left')\n",
    "        \n",
    "        # Handle missing values\n",
    "        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "        \n",
    "        # Basic features\n",
    "        df['log_total_sqft'] = np.log1p(df['total_sqft'])\n",
    "        df['total_sqft_squared'] = df['total_sqft'] ** 2\n",
    "        df['bath_ratio'] = df['bath'] / df['size']\n",
    "        df['bath_per_sqft'] = df['bath'] * 1000 / df['total_sqft']\n",
    "        df['extra_bath'] = df['bath'] - df['size']\n",
    "        df['sqft_per_room'] = df['total_sqft'] / df['size']\n",
    "        \n",
    "        # Price features for training\n",
    "        if is_train:\n",
    "            df['price_per_sqft'] = df['price'] * 100000 / df['total_sqft']\n",
    "            self.price_stats = df.groupby('location')['price'].agg(['mean', 'median', 'std']).fillna(method='ffill')\n",
    "            self.location_price_map = df.groupby('location')['price'].mean().to_dict()\n",
    "            \n",
    "        # Location features\n",
    "        df = self.create_location_features(df)\n",
    "        \n",
    "        # Distance features\n",
    "        df['log_dist'] = np.log1p(df['dist_from_city'])\n",
    "        df['dist_squared'] = df['dist_from_city'] ** 2\n",
    "        df['dist_per_sqft'] = df['dist_from_city'] / df['total_sqft']\n",
    "        \n",
    "        # Rent features\n",
    "        df['log_rent'] = np.log1p(df['avg_2bhk_rent'])\n",
    "        df['rent_ratio'] = df['avg_2bhk_rent'] / df['total_sqft']\n",
    "        df['rent_per_room'] = df['avg_2bhk_rent'] / df['size']\n",
    "        \n",
    "        # Interaction features\n",
    "        df['sqft_bath'] = df['log_total_sqft'] * df['bath_ratio']\n",
    "        df['sqft_dist'] = df['log_total_sqft'] * df['log_dist']\n",
    "        df['bath_dist'] = df['bath_ratio'] * df['log_dist']\n",
    "        \n",
    "        # Ready to move feature\n",
    "        df['ready_to_move'] = (df['availability'] == 'Ready To Move').astype(int)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def prepare_features(self, df, is_train=True):\n",
    "        if self.features is None:\n",
    "            self.features = [\n",
    "                'total_sqft', 'log_total_sqft', 'total_sqft_squared',\n",
    "                'bath', 'bath_ratio', 'bath_per_sqft', 'extra_bath',\n",
    "                'size', 'sqft_per_room', 'location_cluster',\n",
    "                'log_dist', 'dist_squared', 'dist_per_sqft',\n",
    "                'log_rent', 'rent_ratio', 'rent_per_room',\n",
    "                'sqft_bath', 'sqft_dist', 'bath_dist',\n",
    "                'ready_to_move', 'area_type'\n",
    "            ]\n",
    "        \n",
    "        X = df[self.features]\n",
    "        \n",
    "        # Add polynomial features for key numeric columns\n",
    "        numeric_features = ['total_sqft', 'bath_ratio', 'log_dist']\n",
    "        poly_features = self.poly.fit_transform(X[numeric_features]) if is_train else \\\n",
    "                       self.poly.transform(X[numeric_features])\n",
    "        poly_df = pd.DataFrame(poly_features, columns=[f'poly_{i}' for i in range(poly_features.shape[1])])\n",
    "        \n",
    "        X = pd.concat([X, poly_df], axis=1)\n",
    "        \n",
    "        if is_train:\n",
    "            X = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns)\n",
    "        else:\n",
    "            X = pd.DataFrame(self.scaler.transform(X), columns=X.columns)\n",
    "            \n",
    "        return X\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        print(\"Preprocessing data...\")\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Clean size and sqft\n",
    "        df['size'] = df['size'].apply(self.clean_size)\n",
    "        df['total_sqft'] = df['total_sqft'].apply(self.clean_total_sqft)\n",
    "        \n",
    "        # Remove outliers for training data\n",
    "        if is_train:\n",
    "            # Price per sqft based outlier removal\n",
    "            df['price_per_sqft'] = df['price'] * 100000 / df['total_sqft']\n",
    "            for location in df['location'].unique():\n",
    "                location_df = df[df['location'] == location]\n",
    "                if len(location_df) >= 10:  # Only for locations with enough samples\n",
    "                    mean = location_df['price_per_sqft'].mean()\n",
    "                    std = location_df['price_per_sqft'].std()\n",
    "                    df = df[~((df['location'] == location) & \n",
    "                            (df['price_per_sqft'] > mean + 3 * std))]\n",
    "            \n",
    "            # Remove unrealistic bath counts\n",
    "            df = df[df['bath'] <= df['size'] + 2]\n",
    "            \n",
    "            # Remove extreme sqft per bedroom properties\n",
    "            df['sqft_per_bedroom'] = df['total_sqft'] / df['size']\n",
    "            df = df[(df['sqft_per_bedroom'] >= 300) & \n",
    "                    (df['sqft_per_bedroom'] <= 3000)]\n",
    "        \n",
    "        # Handle missing values\n",
    "        df['size'] = df['size'].fillna(df['size'].median())\n",
    "        df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "        df['balcony'] = df['balcony'].fillna(df['balcony'].median())\n",
    "        \n",
    "        # Transform area_type\n",
    "        if is_train:\n",
    "            df['area_type'] = self.le.fit_transform(df['area_type'])\n",
    "        else:\n",
    "            df['area_type'] = self.le.transform(df['area_type'])\n",
    "        \n",
    "        return df\n",
    "    def train_model(self):\n",
    "        print(\"Starting model training...\")\n",
    "        self.train = self.preprocess_data(self.train, is_train=True)\n",
    "        self.train = self.engineer_features(self.train, is_train=True)\n",
    "        \n",
    "        X = self.prepare_features(self.train, is_train=True)\n",
    "        y = self.train['price']\n",
    "        \n",
    "        xgb_models = []\n",
    "        lgb_models = []\n",
    "        cat_models = []\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # XGBoost\n",
    "            xgb_model = xgb.XGBRegressor(\n",
    "                n_estimators=3000,\n",
    "                learning_rate=0.003,\n",
    "                max_depth=9,\n",
    "                min_child_weight=5,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.6,\n",
    "                reg_lambda=0.6,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # LightGBM\n",
    "            lgb_model = lgb.LGBMRegressor(\n",
    "                n_estimators=3000,\n",
    "                learning_rate=0.003,\n",
    "                num_leaves=40,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.6,\n",
    "                reg_lambda=0.6,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # CatBoost\n",
    "            cat_model = cb.CatBoostRegressor(\n",
    "                iterations=3000,\n",
    "                learning_rate=0.003,\n",
    "                depth=9,\n",
    "                l2_leaf_reg=5,\n",
    "                random_state=42,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Train models\n",
    "            xgb_model.fit(X_train, y_train)\n",
    "            lgb_model.fit(X_train, y_train)\n",
    "            cat_model.fit(X_train, y_train)\n",
    "            \n",
    "            xgb_models.append(xgb_model)\n",
    "            lgb_models.append(lgb_model)\n",
    "            cat_models.append(cat_model)\n",
    "            \n",
    "            # Blend predictions\n",
    "            xgb_pred = xgb_model.predict(X_val)\n",
    "            lgb_pred = lgb_model.predict(X_val)\n",
    "            cat_pred = cat_model.predict(X_val)\n",
    "            \n",
    "            blend_pred = (0.4 * xgb_pred + 0.3 * lgb_pred + 0.3 * cat_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, blend_pred))\n",
    "            print(f\"Fold {fold} RMSE: {rmse:.2f}\")\n",
    "        \n",
    "        self.models = {\n",
    "            'xgb': xgb_models,\n",
    "            'lgb': lgb_models,\n",
    "            'cat': cat_models\n",
    "        }\n",
    "     \n",
    "    def predict(self):\n",
    "        print(\"Generating predictions...\")\n",
    "        self.test = self.preprocess_data(self.test, is_train=False)\n",
    "        self.test = self.engineer_features(self.test, is_train=False)\n",
    "        X_test = self.prepare_features(self.test, is_train=False)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        xgb_preds = np.mean([model.predict(X_test) for model in self.models['xgb']], axis=0)\n",
    "        lgb_preds = np.mean([model.predict(X_test) for model in self.models['lgb']], axis=0)\n",
    "        cat_preds = np.mean([model.predict(X_test) for model in self.models['cat']], axis=0)\n",
    "        \n",
    "        # Weighted blend\n",
    "        final_preds = (0.4 * xgb_preds + 0.3 * lgb_preds + 0.3 * cat_preds)\n",
    "        \n",
    "        # Create submission\n",
    "        submission = pd.DataFrame({\n",
    "            'ID': range(len(final_preds)),\n",
    "            'Price': final_preds\n",
    "        })\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "        print(\"Predictions saved to 'submission.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = HousePricePredictor()\n",
    "    predictor.load_data()\n",
    "    predictor.train_model()\n",
    "    predictor.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
